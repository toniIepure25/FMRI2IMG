stages:
  prepare_data:
    cmd: python -m fmri2image.data.download_nsd --raw_root data/raw
    deps:
      - src/fmri2image/data/download_nsd.py
      - configs/paths/paths.yaml
    outs:
      - data/raw/nsd:
          persist: true

  roi_extract:
    cmd: >
      python -m fmri2image.data.extract_roi
      --fmriprep_dir data/processed/nsd/fmriprep
      --out_dir data/processed/nsd/roi
      --mode atlas
      --atlas glasser
      --vector_dim 2048
      --subject subj01
    deps:
      - src/fmri2image/data/extract_roi.py
      - configs/data/nsd.yaml
    outs:
      - data/processed/nsd/roi:
          persist: true

  # === UPDATED: OpenCLIP text embeddings (writes .npy + .pkl) ===
  clip_text:
    cmd: >
      python -m fmri2image.text.clip_text_openclip
      --captions data/raw/nsd/captions.csv
      --out_npy data/processed/nsd/clip_text.npy
      --out_pkl data/processed/nsd/clip_text_meta.pkl
      --model ViT-B-32
      --pretrained laion2b_s34b_b79k
    deps:
      - src/fmri2image/text/clip_text_openclip.py
      - src/fmri2image/embeddings/clip_utils.py
      - data/raw/nsd/captions.csv
    outs:
      - data/processed/nsd/clip_text.npy:
          persist: true
      - data/processed/nsd/clip_text_meta.pkl:
          persist: true

  # === NEW: OpenCLIP image embeddings (optional but recommended) ===
  clip_image:
    cmd: >
      python -m fmri2image.vision.clip_image_openclip
      --images_root data/raw/nsd/images
      --out_npy data/processed/nsd/clip_img.npy
      --out_pkl data/processed/nsd/clip_img_meta.pkl
      --model ViT-B-32
      --pretrained laion2b_s34b_b79k
    deps:
      - src/fmri2image/vision/clip_image_openclip.py
      - src/fmri2image/embeddings/clip_utils.py
      - data/raw/nsd/images
    outs:
      - data/processed/nsd/clip_img.npy:
          persist: true
      - data/processed/nsd/clip_img_meta.pkl:
          persist: true

  baseline_train:
    cmd: python -m fmri2image.cli ++run.name=baseline_train train=baseline
    deps:
      - src/fmri2image/pipelines/baseline_train.py
      - src/fmri2image/models/encoders/mlp_encoder.py
      - src/fmri2image/data/nsd_reader.py
      - configs/train/baseline.yaml
      - configs/config.yaml
      - data/processed/nsd/roi/subj01_roi.npy
      - data/processed/nsd/clip_text.npy
    outs:
      - outputs

  pretrain_encoder:
    cmd: >
      python -m fmri2image.selfsupervised.pretrain_fmri
      --images_root data/raw/nsd/images
      --fmri_root data/raw/nsd/fmri
      --captions data/raw/nsd/captions.csv
      --roi_dir data/processed/nsd/roi
      --subject subj01
      --dim 2048
      --mask_ratio 0.5
      --lr 1e-3
      --epochs 2
      --batch_size 16
      --num_workers 4
      --out_ckpt data/artifacts/encoder_pretrained.ckpt
    deps:
      - src/fmri2image/selfsupervised/pretrain_fmri.py
      - src/fmri2image/data/nsd_reader.py
      - data/processed/nsd/roi/subj01_roi.npy
    outs:
      - data/artifacts/encoder_pretrained.ckpt
